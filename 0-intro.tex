\section{Introduction}

Choreographic programming~\citep{montesi-thesis, montesi-textbook} is a paradigm for programming distributed systems that run on multiple nodes.
%
In choreographic programming, the programmer writes one, unified program --- called a \emph{choreography} --- which defines the entire behavior of a distributed system.
%
The choreography is then compiled to individual programs for each node through a process called \emph{endpoint projection}.
%
For example, the choreography in \Cref{fig:pipeline} defines a distributed data processing pipeline:~\footnote{The code is written in Async HasChor with some uninteresting details omitted. We enable the \texttt{LambdaCase} GHC extension, which allows using \hs{\case} to define a function that immediately pattern matches on its argument.}  
%
a piece of data is read at Alice, passed around among Alice, Bob, and Carol, with each applying their respective processing function \texttt{f}, \texttt{g}, and \texttt{h} to the data, and output at Carol;
%
the choreography repeats if there is more data to process.

\begin{figure}[h]
\centering
\begin{minipage}{0.5\textwidth}
\begin{minted}[autogobble]{haskell}
  pipeline :: Choreo ()
  pipeline = do
    x <- locally @Alice getInput
    y <- comm @Alice @Bob   (f x)
    z <- comm @Bob   @Carol (g y)
    locally @Carol (showOutput (h z))

    cond @Alice haveMore \case 
      True -> return ()
      False -> pipeline
\end{minted}
\end{minipage}
\caption{A choreography for a distributed data processing pipeline}
\label{fig:pipeline}
\end{figure}

The \hs{pipeline} choreography showcases the three core operators of choreographic programming: \hs{locally} for local computations, \hs{comm} for communicating data, and \hs{cond} for conditional execution.
%
Applying endpoint projection to the \hs{pipeline} choreography for Alice, Bob, and Carol will generate the three individual network programs respectively in \Cref{fig:pipeline-epp}.
%
Note that although the original choreography is expressed sequentially, the generated individual programs will run in parallel, with each node processing the next batch of data without waiting for the downstream nodes.

\begin{figure}[t]
\hspace{1cm}
\begin{minipage}[t]{0.3\textwidth}
\begin{minted}{haskell}
alice = do
  x <- getInput
  send @Bob (f x)

  t <- haveMore
  send @Bob   t 
  send @Carol t
  case t of
    True -> return ()
    False -> alice
\end{minted}
\end{minipage}
\begin{minipage}[t]{0.3\textwidth}
\begin{minted}{haskell}
bob = do
  y <- recv @Alice
  send @Carol (g y)

  t <- recv @Alice 
  case t of 
    True -> return ()
    False -> bob
\end{minted}
\end{minipage}
\begin{minipage}[t]{0.3\textwidth}
\begin{minted}{haskell}
carol = do
  z <- recv @Bob
  showOutput (h z)

  t <- recv @Bob
  case t of
    True -> return ()
    False -> carol
\end{minted}
\end{minipage}
\caption{Individual network programs generated from the \hs{pipeline} choreography}
\label{fig:pipeline-epp}
\end{figure}

Choreographies, with their global point of view, make communication among nodes manifest and guaranteed to match on both ends, resutling in a a deadlock-free-by-design construction~\citep{deadlock-free-by-design}.
%
In the last decade, several choreographic programming languages have been proposed~\citep{aiocj, choral, pirouette, CC, chor-lambda}, and they have been applied to build real-world protocols such as IRC~\citep{irc}.
%
More rencently, \emph{library-level} choreographic programming, which embeds choreographic programming in a host language and thus provides a lightweight way to bring choreographic programming to existing languages, have begun to emerge~\citep{haschor, chorus}.

Despite these developments, existing choreographic programming languages often assume an unrealistic model where the underlying network is synchronous and lossless.
%
This assumption significantly litmits the efficiency and expressiveness of a choreography:
%
(1) a communication would block both the sender and receiver, preventing them from performing other tasks and recuding concurrency;
%
(2) it is impossible to handle message delays and losses, which are ubiquitous and challenging in distributed system programming.
%
Previous work addresses some of these issues, but it is either unwieldy or suffers from other problems, which we discuss in more detail in \Cref{sec:related}.

In this paper, we introduce a new choreographic programming model that supports asynchronous communication and develop \emph{Async HasChor}, a library-level choreographic programming language in Haskell that implemnts our model.
%
Async HasChor incorporates \emph{futures} --- a placeholder for a value that will be available in the future --- into choreographic programming.
%
It makes each communication return a future to represent a yet-to-arrive message.
%
A node can wait on a future, and if the corresponding message has arrived, the carried value will be immediately available for use;
%
if the message has not arrived, the node's execution will be blocked.
%
A node can also perform a series of communications and wait for their results.
%
This allows message passings to be executed in parallel, reducing network latency.
%
Furthermore, a node can wait on a quorum of results and makes a decision based on that.
%
This allows the system to tolerate network or machine failure while maintaining consistency.

Async HasChor enables programmers to express distributed protocols that were impossible before, but it also introduces significant challenges to endpoint projection.
%
In addition to using asynchronous sending and receiving in network programs, endpoint projection must also handle out-of-order messages.
%
Otherwise, a message could be assigned to the wrong variable, breaking the safety guarantees and leading to catastrophic consequences.
%
Following standard practice, we attach a sequence number to each message to help the receiver distinguish between them.
%
Once again, we leverage the global perspective provided by a choreography to generate these sequence numbers \emph{automatically} and \emph{consistently} during endpoint projection.

Following HasChor, Async HasChor is built on top of freer monads and offers a monadic interface for choreographic programming.
%
Endpoint projection is straightforwardly implemented by interpreting the effects in a freer monad based on a projection target.
%
We piggyback on the host language, Haskell, to provide an asynchronous runtime for executing futures, so we do not have to build our own.
%
We believe our model is general and can be implemented by different approaches in other languages.

\vspace{10pt}
\noindent \textit{\textbf{Contributions.}} The paper makes the following contributions:
%
\begin{itemize}
\item
    We examine the issues with synchronous communication in choreographic programming, the challenges of making them asynchronous, and our solution based on sequence numbers~(\Cref{sec:motiv}).
\item
    We give a tour of Async HasChor, our choreographic programming language that supports asynchronous communication, and show it enpowers programms to express distributed protocols previously impossible~(\Cref{sec:tour}).
\item
    We implement Async HasChor as a library-level choreographic language in Haskell, using freer monads with sequence numbers automatically generated during endpoint projection.(\Cref{sec:impl}).
\item
    We present a formal model of Async HasChor and sketch a proof of deadlock freedom~(\Cref{sec:formal}).
\end{itemize}
%
We discuss related work in \Cref{sec:related} and conclude in \Cref{sec:conclu}.
